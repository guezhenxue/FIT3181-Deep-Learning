{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guezhenxue/FIT3181-Deep-Learning/blob/main/FIT5215_FIT3181_In_class_Kaggle_Competition_Week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHNAq9QI7vQn"
      },
      "source": [
        "# FIT5215/FIT3181: In-class Kaggle Competition\n",
        "\n",
        "# <span style=\"color:#0b486b\"> Week 2 </span>\n",
        "\n",
        "**Your roles:**\n",
        "- Implement a feedforward neural net for a multi-class classfication problem using PyTorch\n",
        "- Train models, finetune hyper-parameters\n",
        "- Predict trained model on the test set and submit your solution to Kaggle.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIg_vVMU_pU4"
      },
      "source": [
        "### <span style=\"color:#0b486b\"> II.0 Running on Google Colab</span> <span style=\"color:red\"></span>\n",
        "You will need to download relevant files to run this notebook on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUu6Lil9FUsi",
        "outputId": "800a8efb-056f-4a31-ed47-b49c04311f9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UxKyCyMxTfew8zNcbel6GJOHja2gIuSs\n",
            "To: /content/Data_kaggle_week2.zip\n",
            "\r  0% 0.00/377k [00:00<?, ?B/s]\r100% 377k/377k [00:00<00:00, 115MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/file/d/1UxKyCyMxTfew8zNcbel6GJOHja2gIuSs/view?usp=sharing --fuzzy -O Data_kaggle_week2.zip  # Comment out this line of code if you have already run it once\n",
        "# backup urls\n",
        "\n",
        "# !gdown https://drive.google.com/file/d/1T-tM1CT6TkpZhWwF-cjyOr-xwc03X3lI/view?usp=sharing --fuzzy -O Data_kaggle_week2.zip\n",
        "\n",
        "# !gdown https://drive.google.com/file/d/13zoGHKtAOvi5vMnDZalqMRoA849JhXhJ/view?usp=sharing --fuzzy -O Data_kaggle_week2.zip\n",
        "\n",
        "# !gdown https://drive.google.com/file/d/1SNlYnnT-lRl7ly73WVK5vs2dnjak5OY0/view?usp=sharing --fuzzy -O Data_kaggle_week2.zip\n",
        "\n",
        "# !gdown https://drive.google.com/file/d/1cAyNRb_tqDEImUOCMh3w2rZw44hobl1r/view?usp=sharing --fuzzy -O Data_kaggle_week2.zip\n",
        "\n",
        "# !gdown https://drive.google.com/file/d/1r3PZLRVOLk8Z5sh3wZgBD8M86rIInnxL/view?usp=sharing --fuzzy -O Data_kaggle_week2.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ikNF3Vj_0nT"
      },
      "outputs": [],
      "source": [
        "!unzip -q Data_kaggle_week2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn9fOkEguNwv"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Description:\n",
        "\n",
        "The database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number.\n",
        "\n",
        "The database is a (tiny) sub-area of a scene, consisting of 82 x 100 pixels. Each line of data corresponds to a 3x3 square neighbourhood of pixels completely contained within the 82x100 sub-area. Each line contains the pixel values in the four spectral bands (converted to ASCII) of each of the 9 pixels in the 3x3 neighbourhood and a number indicating the classification label of the central pixel.\n",
        "\n",
        "Each pixel is categorized as one of the following classes:\n",
        "- 1 red soil\n",
        "- 2 cotton crop\n",
        "- 3 grey soil\n",
        "- 4 damp grey soil\n",
        "- 5 soil with vegetation stubble\n",
        "- 6 very damp grey soil\n",
        "\n",
        "#### Attribute information\n",
        "\n",
        "There are 36 predictive attributes (= 4 spectral bands x 9 pixels in neighborhood). In each line of data the four spectral values for the top-left pixel are given first followed by the four spectral values for the top-middle pixel and then those for the top-right pixel, and so on with the pixels read out in sequence left-to-right and top-to-bottom. Thus, the four spectral values for the central pixel are given by attributes 17,18,19 and 20. **If you like you can use only these four attributes, while ignoring the others.** This avoids the problem which arises when a 3x3 neighbourhood straddles a boundary."
      ],
      "metadata": {
        "id": "K7KHBNFSH0WM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gOafwlzDKOs",
        "tags": []
      },
      "source": [
        "#### <span style=\"color:#0b486b\">1. Data Processing </span>\n",
        "\n",
        "We use `sklearn` to load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwTUzYB7_8Ec"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_svmlight_file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def seed_all(seed=1029):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_all(1029)"
      ],
      "metadata": {
        "id": "m8b7i8gsdZbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJZYOkYKFUsj"
      },
      "source": [
        "#### Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA7JBIeyDUaL",
        "outputId": "f5b9ba4e-af3d-4c49-fc6f-5afc3c3562cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X data shape: (4435, 36)\n",
            "y data shape: (4435, 1)\n",
            "# classes: 6\n",
            "[1. 2. 3. 4. 5. 6.]\n"
          ]
        }
      ],
      "source": [
        "data_file_name= \"dataset.libsvm\"\n",
        "data_file = os.path.abspath(\"./Data_kaggle_week2/\" + data_file_name)\n",
        "X_data, y_data = load_svmlight_file(data_file)\n",
        "X_data= X_data.toarray()\n",
        "y_data= y_data.reshape(y_data.shape[0],-1)\n",
        "print(\"X data shape: {}\".format(X_data.shape))\n",
        "print(\"y data shape: {}\".format(y_data.shape))\n",
        "print(\"# classes: {}\".format(len(np.unique(y_data))))\n",
        "print(np.unique(y_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94QPzvONDeXn"
      },
      "source": [
        "We use `sklearn` to split the dataset into the train and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SQRKrWYDfDB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "def train_valid_split(data, target, valid_size):\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(data, target, test_size = valid_size, random_state= 33)\n",
        "    return X_train, X_valid, y_train, y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHPaCsCEDieq"
      },
      "outputs": [],
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y_data.ravel())\n",
        "y_data= le.transform(y_data.ravel())\n",
        "y_data = y_data.ravel()\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_valid_split(X_data, y_data, valid_size=0.3)\n",
        "y_train= y_train.reshape(-1)\n",
        "y_valid= y_valid.reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXXeRuOCFUsk"
      },
      "source": [
        "#### Load Unlabelled Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIVgMdT9FUsk",
        "outputId": "c818b193-f2ab-40c3-ea19-b8700e19328b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data shape: (2000, 36)\n"
          ]
        }
      ],
      "source": [
        "data_file_name= \"test_unlabelled.libsvm\"\n",
        "data_file = os.path.abspath(\"./Data_kaggle_week2/\" + data_file_name)\n",
        "X_test, _ = load_svmlight_file(data_file)\n",
        "X_test= X_test.toarray()\n",
        "print(\"Test data shape: {}\".format(X_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkTrTUk1FUsk",
        "outputId": "fb972201-c260-4748-88fd-3b7947ed7175",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3104, 36) (1331, 36)\n",
            "(3104,) (1331,)\n",
            "lables: [0 1 2 3 4 5]\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, X_valid.shape)\n",
        "print(y_train.shape, y_valid.shape)\n",
        "print(\"lables: {}\".format(np.unique(y_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-1aTLG9OlDY"
      },
      "source": [
        "#### Batching Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsctBVoZOxfI"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, labels=None):\n",
        "        super(MyDataset, self).__init__()\n",
        "        self.data = torch.tensor(data, dtype = torch.float32)\n",
        "        if labels is None:\n",
        "            self.labels = torch.ones(self.data.shape[0], dtype = torch.float32)\n",
        "        else:\n",
        "            self.labels = torch.tensor(labels, dtype = torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM-maEstPJVs"
      },
      "outputs": [],
      "source": [
        "train_data = MyDataset(X_train, y_train)\n",
        "valid_data = MyDataset(X_valid, y_valid)\n",
        "test_data = MyDataset(X_test, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze6bpw7XPld4"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7R0wK3rD17J",
        "outputId": "902886b8-bc6a-4ddf-8dbc-f06deabd55ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 3104, # features: 36, and number of classes: 6\n"
          ]
        }
      ],
      "source": [
        "train_size= int(X_train.shape[0])\n",
        "n_features= int(X_train.shape[1])\n",
        "n_classes= len(np.unique(y_train))\n",
        "print(f\"Train size: {train_size}, # features: {n_features}, and number of classes: {n_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4DwRYFrD7Ph"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lONGkEhfD8MT"
      },
      "source": [
        "#### <span style=\"color:#0b486b\">2. Build up the model </span>\n",
        "\n",
        "We build up a feedforward neural network in PyTorch. Note that we only return the logits because the cross-entropy loss we use later includes the softmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0QiW3knFPFG"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "dnn_model = Sequential(Linear(n_features,10), nn.ReLU(),\n",
        "                       Linear(10,20), nn.ReLU(),\n",
        "                       Linear(20,15), nn.ReLU(),\n",
        "                       Linear(15, n_classes)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d-bvn6EhtZm"
      },
      "outputs": [],
      "source": [
        "def compute_loss(model, loss_fn, loader, device):\n",
        "\tloss = 0\n",
        "\tfor (batchX, batchY) in loader:\n",
        "\t\tbatchX, batchY = batchX.to(device), batchY.to(device)\n",
        "\t\tloss += loss_fn(model(batchX.type(torch.float32)), batchY.type(torch.long))\n",
        "\treturn float(loss)/len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1MF5boRiPeS"
      },
      "outputs": [],
      "source": [
        "def compute_acc(model, loader, device):\n",
        "\tmodel.eval()\n",
        "\t# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "\twith torch.no_grad():\n",
        "\t\tcorrects = 0\n",
        "\t\ttotals =0\n",
        "\t\tfor (batchX, batchY) in loader:\n",
        "\t\t\tbatchX, batchY = batchX.to(device), batchY.to(device)\n",
        "\t\t\toutputs = model(batchX.type(torch.float32)) #feed batch to the model\n",
        "\t\t\ttotals += batchY.size(0) #accumulate totals with the current batch size\n",
        "\t\t\tpredicted = torch.argmax(outputs.data, 1) #get the predicted class\n",
        "\t\t\tcorrects += (predicted == batchY.type(torch.long)).sum().item() #accumulate correct predictions\n",
        "\tacc = float(corrects)/totals #compute the accuracy\n",
        "\treturn acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "PMcynhEEFUsl"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "\tdnn_model = Sequential(Linear(n_features,10), nn.ReLU(),\n",
        "                         Linear(10,20), nn.ReLU(),\n",
        "                         Linear(20,15), nn.ReLU(),\n",
        "                         Linear(15, n_classes))\n",
        "\treturn dnn_model\n",
        "\n",
        "def fit(model= None, train_loader = None, valid_loader = None, loss_fn = None, optimizer = torch.optim.Adam,\n",
        "\t\t\t\tlearning_rate=0.001, num_epochs = 100, verbose = True, seed= 1234, device=None):\n",
        "\ttorch.manual_seed(seed)\n",
        "\toptim = optimizer(model.parameters(), lr = learning_rate)\n",
        "\thistory = dict()\n",
        "\thistory['val_loss'] = list()\n",
        "\thistory['val_acc'] = list()\n",
        "\thistory['train_loss'] = list()\n",
        "\thistory['train_acc'] = list()\n",
        "\tfor epoch in range(num_epochs):\n",
        "\t\tfor i, (X, y) in enumerate(train_loader):\n",
        "\t\t\t# Forward pass\n",
        "\t\t\tX, y = X.to(device), y.to(device)\n",
        "\t\t\toutputs = model(X.type(torch.float32))\n",
        "\t\t\tloss = loss_fn(outputs, y.type(torch.long))\n",
        "\t\t\t# Backward and optimize\n",
        "\t\t\toptim.zero_grad()\n",
        "\t\t\tloss.backward()\n",
        "\t\t\toptim.step()\n",
        "\t\t#losses and accuracies for epoch\n",
        "\t\tval_loss = compute_loss(model, loss_fn, valid_loader, device)\n",
        "\t\tval_acc = compute_acc(model, valid_loader, device)\n",
        "\t\ttrain_loss = compute_loss(model, loss_fn, train_loader, device)\n",
        "\t\ttrain_acc = compute_acc(model, train_loader, device)\n",
        "\t\ttest_acc = compute_acc(model, test_loader, device)\n",
        "\t\thistory['val_loss'].append(val_loss)\n",
        "\t\thistory['val_acc'].append(val_acc)\n",
        "\t\thistory['train_loss'].append(train_loss)\n",
        "\t\thistory['train_acc'].append(train_acc)\n",
        "\t\tif not verbose: #verbose = True means we do not show the training information during training\n",
        "\t\t\tprint(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\t\t\tprint(f\"train loss= {train_loss:.4f} - train acc= {train_acc*100:.2f}% - valid loss= {val_loss:.4f} - valid acc= {val_acc*100:.4f}%\")\n",
        "\treturn history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhS0V0V9omqD",
        "tags": []
      },
      "source": [
        "#### <span style=\"color:#0b486b\">4. Declaring the Loss, Optimizer, learning rate and Training the Model </span>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmPbreigIJ5t",
        "outputId": "4b0c144f-d497-4c52-ff2b-6df4271db3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "train loss= 1.6582 - train acc= 37.76% - valid loss= 1.6619 - valid acc= 37.4155%\n",
            "Epoch 2/100\n",
            "train loss= 1.4213 - train acc= 52.35% - valid loss= 1.4195 - valid acc= 51.7656%\n",
            "Epoch 3/100\n",
            "train loss= 1.1264 - train acc= 56.51% - valid loss= 1.1318 - valid acc= 56.1232%\n",
            "Epoch 4/100\n",
            "train loss= 0.7825 - train acc= 81.44% - valid loss= 0.7779 - valid acc= 81.8182%\n",
            "Epoch 5/100\n",
            "train loss= 0.5445 - train acc= 81.64% - valid loss= 0.5462 - valid acc= 82.0436%\n",
            "Epoch 6/100\n",
            "train loss= 0.4616 - train acc= 82.99% - valid loss= 0.4610 - valid acc= 82.7949%\n",
            "Epoch 7/100\n",
            "train loss= 0.4215 - train acc= 84.15% - valid loss= 0.4281 - valid acc= 84.2224%\n",
            "Epoch 8/100\n",
            "train loss= 0.4080 - train acc= 85.37% - valid loss= 0.4178 - valid acc= 84.9737%\n",
            "Epoch 9/100\n",
            "train loss= 0.3953 - train acc= 84.95% - valid loss= 0.3955 - valid acc= 84.8234%\n",
            "Epoch 10/100\n",
            "train loss= 0.3770 - train acc= 85.28% - valid loss= 0.3816 - valid acc= 85.0488%\n",
            "Epoch 11/100\n",
            "train loss= 0.4987 - train acc= 81.60% - valid loss= 0.5345 - valid acc= 81.3674%\n",
            "Epoch 12/100\n",
            "train loss= 0.3604 - train acc= 85.92% - valid loss= 0.3720 - valid acc= 84.7483%\n",
            "Epoch 13/100\n",
            "train loss= 0.3460 - train acc= 86.24% - valid loss= 0.3642 - valid acc= 85.4996%\n",
            "Epoch 14/100\n",
            "train loss= 0.3639 - train acc= 85.18% - valid loss= 0.3878 - valid acc= 84.8986%\n",
            "Epoch 15/100\n",
            "train loss= 0.3519 - train acc= 85.76% - valid loss= 0.3720 - valid acc= 85.2742%\n",
            "Epoch 16/100\n",
            "train loss= 0.3357 - train acc= 86.11% - valid loss= 0.3561 - valid acc= 85.2742%\n",
            "Epoch 17/100\n",
            "train loss= 0.3344 - train acc= 87.08% - valid loss= 0.3599 - valid acc= 85.1991%\n",
            "Epoch 18/100\n",
            "train loss= 0.3262 - train acc= 87.24% - valid loss= 0.3491 - valid acc= 86.1007%\n",
            "Epoch 19/100\n",
            "train loss= 0.3180 - train acc= 87.50% - valid loss= 0.3480 - valid acc= 86.6266%\n",
            "Epoch 20/100\n",
            "train loss= 0.3250 - train acc= 87.18% - valid loss= 0.3514 - valid acc= 85.8753%\n",
            "Epoch 21/100\n",
            "train loss= 0.3181 - train acc= 87.69% - valid loss= 0.3538 - valid acc= 86.9271%\n",
            "Epoch 22/100\n",
            "train loss= 0.3125 - train acc= 87.66% - valid loss= 0.3469 - valid acc= 86.4763%\n",
            "Epoch 23/100\n",
            "train loss= 0.3432 - train acc= 86.82% - valid loss= 0.3816 - valid acc= 86.1758%\n",
            "Epoch 24/100\n",
            "train loss= 0.3202 - train acc= 87.50% - valid loss= 0.3525 - valid acc= 86.1758%\n",
            "Epoch 25/100\n",
            "train loss= 0.3038 - train acc= 87.95% - valid loss= 0.3441 - valid acc= 86.5515%\n",
            "Epoch 26/100\n",
            "train loss= 0.3116 - train acc= 88.31% - valid loss= 0.3533 - valid acc= 86.4012%\n",
            "Epoch 27/100\n",
            "train loss= 0.3124 - train acc= 87.63% - valid loss= 0.3534 - valid acc= 85.8002%\n",
            "Epoch 28/100\n",
            "train loss= 0.3031 - train acc= 88.34% - valid loss= 0.3422 - valid acc= 86.2509%\n",
            "Epoch 29/100\n",
            "train loss= 0.3366 - train acc= 86.79% - valid loss= 0.3890 - valid acc= 83.9219%\n",
            "Epoch 30/100\n",
            "train loss= 0.3003 - train acc= 88.79% - valid loss= 0.3529 - valid acc= 86.7769%\n",
            "Epoch 31/100\n",
            "train loss= 0.3173 - train acc= 87.76% - valid loss= 0.3764 - valid acc= 84.8986%\n",
            "Epoch 32/100\n",
            "train loss= 0.3008 - train acc= 87.98% - valid loss= 0.3434 - valid acc= 86.1758%\n",
            "Epoch 33/100\n",
            "train loss= 0.2982 - train acc= 88.60% - valid loss= 0.3510 - valid acc= 86.0255%\n",
            "Epoch 34/100\n",
            "train loss= 0.2922 - train acc= 88.60% - valid loss= 0.3439 - valid acc= 86.4012%\n",
            "Epoch 35/100\n",
            "train loss= 0.2891 - train acc= 88.89% - valid loss= 0.3470 - valid acc= 86.9271%\n",
            "Epoch 36/100\n",
            "train loss= 0.2958 - train acc= 88.50% - valid loss= 0.3502 - valid acc= 86.5515%\n",
            "Epoch 37/100\n",
            "train loss= 0.3455 - train acc= 86.37% - valid loss= 0.3943 - valid acc= 84.3727%\n",
            "Epoch 38/100\n",
            "train loss= 0.3009 - train acc= 89.05% - valid loss= 0.3644 - valid acc= 86.3261%\n",
            "Epoch 39/100\n",
            "train loss= 0.3245 - train acc= 87.18% - valid loss= 0.3922 - valid acc= 84.9737%\n",
            "Epoch 40/100\n",
            "train loss= 0.2947 - train acc= 88.98% - valid loss= 0.3644 - valid acc= 87.0023%\n",
            "Epoch 41/100\n",
            "train loss= 0.2809 - train acc= 89.56% - valid loss= 0.3474 - valid acc= 87.1525%\n",
            "Epoch 42/100\n",
            "train loss= 0.2839 - train acc= 89.27% - valid loss= 0.3564 - valid acc= 87.0023%\n",
            "Epoch 43/100\n",
            "train loss= 0.2992 - train acc= 88.14% - valid loss= 0.3517 - valid acc= 86.4012%\n",
            "Epoch 44/100\n",
            "train loss= 0.2890 - train acc= 89.53% - valid loss= 0.3624 - valid acc= 86.7017%\n",
            "Epoch 45/100\n",
            "train loss= 0.2877 - train acc= 88.63% - valid loss= 0.3465 - valid acc= 87.0023%\n",
            "Epoch 46/100\n",
            "train loss= 0.3049 - train acc= 88.18% - valid loss= 0.3803 - valid acc= 86.7017%\n",
            "Epoch 47/100\n",
            "train loss= 0.2891 - train acc= 88.76% - valid loss= 0.3513 - valid acc= 85.7250%\n",
            "Epoch 48/100\n",
            "train loss= 0.3159 - train acc= 87.76% - valid loss= 0.3929 - valid acc= 84.9737%\n",
            "Epoch 49/100\n",
            "train loss= 0.2834 - train acc= 89.82% - valid loss= 0.3637 - valid acc= 86.7017%\n",
            "Epoch 50/100\n",
            "train loss= 0.4584 - train acc= 82.12% - valid loss= 0.5006 - valid acc= 81.2171%\n"
          ]
        }
      ],
      "source": [
        "from torch import optim\n",
        "optim_dict = {\"Adam\":optim.Adam, \"Adadelta\":optim.Adadelta, \"Adagrad\":optim.Adagrad,\n",
        "              \"Adamax\":optim.Adamax, \"AdamW\": optim.AdamW, \"ASGD\":optim.ASGD,\n",
        "              \"NAdam\":optim.NAdam, \"RMSprop\":optim.RMSprop, \"RAdam\":optim.RAdam,\n",
        "              \"Rprop\": optim.Rprop, \"SGD\":optim.SGD}\n",
        "\n",
        "dnn_model = create_model().to(device)\n",
        "history = fit(dnn_model, train_loader = train_loader, valid_loader= valid_loader, loss_fn = nn.CrossEntropyLoss(),\n",
        "    optimizer = optim_dict[\"SGD\"], learning_rate = 0.1, num_epochs =100, verbose= False, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3-WS91yTvEL"
      },
      "source": [
        "#### <span style=\"color:#0b486b\">5. Visualizing the Performance and Loss Objective Function </span>\n",
        "\n",
        "There are four keys in the history dictionary: `train_loss` and `val_loss` measure the loss on the training set and the validation set, respectively, while `train_acc` and `val_acc` measure the accuracy on the training set and the validation set.  \n",
        "The following figure visualize all four metrics with two y-axes, losses (blue lines, in descending) and accuracies (red lines, in asending)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZVEdlONTuJR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "his = history\n",
        "fig = plt.figure(figsize=(8, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "ln1 = ax.plot(his['train_loss'], 'b--',label='loss')\n",
        "ln2 = ax.plot(his['val_loss'], 'b-',label='val_loss')\n",
        "ax.set_ylabel('loss', color='blue')\n",
        "ax.tick_params(axis='y', colors=\"blue\")\n",
        "\n",
        "ax2 = ax.twinx()\n",
        "ln3 = ax2.plot(his['train_acc'], 'r--',label='accuracy')\n",
        "ln4 = ax2.plot(his['val_acc'], 'r-',label='val_accuracy')\n",
        "ax2.set_ylabel('accuracy', color='red')\n",
        "ax2.tick_params(axis='y', colors=\"red\")\n",
        "\n",
        "lns = ln1 + ln2 + ln3 + ln4\n",
        "labels = [l.get_label() for l in lns]\n",
        "ax.legend(lns, labels, loc=7)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNjeT-EyiRx3"
      },
      "source": [
        "# Evaluate model on the testing set, get the csv file and upload to kaggle\n",
        " - Note: Do not modify this block of code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "180qpEBIFUsl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "def save_prediction_to_csv(model, loader, device, output_file=\"submission.csv\"):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    image_ids = []\n",
        "    df = {\n",
        "    \"ImageId\": [],\n",
        "    \"Label\": []\n",
        "    }\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (batchX, batchY) in enumerate(loader):\n",
        "            batchX, batchY = batchX.to(device), batchY.to(device)\n",
        "            outputs = model(batchX.float())  # Convert to float32 and feed batch to the model\n",
        "            predicted = torch.argmax(outputs, dim=1)  # Get the predicted class\n",
        "            total += predicted.size(0)\n",
        "            for ids, pred in enumerate(predicted):\n",
        "                df[\"Label\"].append(pred.cpu().item())\n",
        "    df[\"ImageId\"] = [i+1 for i in range(total)]\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(df)\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KR3gRHtsGTOm"
      },
      "outputs": [],
      "source": [
        "save_prediction_to_csv(dnn_model, test_loader, device) # should only modify the input model to this function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3UicCvcFUsl"
      },
      "source": [
        "# Submit result to kaggle competition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc9yWR-XFUsl"
      },
      "source": [
        "- Regsiter Kaggle account using your private gmail [Kaggle](https://https://www.kaggle.com/)\n",
        "\n",
        "- Lastly, you will need to download the `submission.csv` file and upload it to the Kaggle competition (url for competition is provided in Moodle).\n",
        "\n",
        "- Remember to change your display your team name on the Leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FdQGl97zVF5Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}